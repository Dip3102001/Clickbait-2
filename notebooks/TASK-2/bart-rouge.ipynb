{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install accelerate -U","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-08T19:57:05.667152Z","iopub.execute_input":"2024-06-08T19:57:05.667496Z","iopub.status.idle":"2024-06-08T19:57:18.058122Z","shell.execute_reply.started":"2024-06-08T19:57:05.667472Z","shell.execute_reply":"2024-06-08T19:57:18.056899Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.31.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!conda install -y gdown","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:57:18.060166Z","iopub.execute_input":"2024-06-08T19:57:18.060462Z","iopub.status.idle":"2024-06-08T19:58:30.884909Z","shell.execute_reply.started":"2024-06-08T19:57:18.060436Z","shell.execute_reply":"2024-06-08T19:58:30.883959Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Channels:\n - rapidsai\n - nvidia\n - conda-forge\n - defaults\n - pytorch\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - gdown\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    packaging-24.0             |     pyhd8ed1ab_0          49 KB  conda-forge\n    pluggy-1.5.0               |     pyhd8ed1ab_0          23 KB  conda-forge\n    requests-2.32.3            |     pyhd8ed1ab_0          57 KB  conda-forge\n    tqdm-4.66.4                |     pyhd8ed1ab_0          87 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         217 KB\n\nThe following NEW packages will be INSTALLED:\n\n  packaging          conda-forge/noarch::packaging-24.0-pyhd8ed1ab_0 \n  pluggy             conda-forge/noarch::pluggy-1.5.0-pyhd8ed1ab_0 \n  requests           conda-forge/noarch::requests-2.32.3-pyhd8ed1ab_0 \n  tqdm               conda-forge/noarch::tqdm-4.66.4-pyhd8ed1ab_0 \n\n\n\nDownloading and Extracting Packages:\ntqdm-4.66.4          | 87 KB     |                                       |   0% \nrequests-2.32.3      | 57 KB     |                                       |   0% \u001b[A\n\npackaging-24.0       | 49 KB     |                                       |   0% \u001b[A\u001b[A\n\n\ntqdm-4.66.4          | 87 KB     | #############5                        |  37% \u001b[A\u001b[A\u001b[A\n\npackaging-24.0       | 49 KB     | ############1                         |  33% \u001b[A\u001b[A\n\n\npluggy-1.5.0         | 23 KB     | #########################4            |  69% \u001b[A\u001b[A\u001b[A\nrequests-2.32.3      | 57 KB     | ##########3                           |  28% \u001b[A\n\n\npluggy-1.5.0         | 23 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\ntqdm-4.66.4          | 87 KB     | ##################################### | 100% \u001b[A\u001b[A\n                                                                                \u001b[A\n                                                                                \u001b[A\n\n                                                                                \u001b[A\u001b[A\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\nPreparing transaction: done\nVerifying transaction: failed\n\nRemoveError: 'packaging' is a dependency of conda and cannot be removed from\nconda's operating environment.\nRemoveError: 'pluggy' is a dependency of conda and cannot be removed from\nconda's operating environment.\nRemoveError: 'requests' is a dependency of conda and cannot be removed from\nconda's operating environment.\nRemoveError: 'tqdm' is a dependency of conda and cannot be removed from\nconda's operating environment.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# https://drive.google.com/file/d/1-649JNvw15TYDciHpMlJKXQ08_2lKJF4/view\n!gdown --id \"1-649JNvw15TYDciHpMlJKXQ08_2lKJF4\"","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:58:30.886300Z","iopub.execute_input":"2024-06-08T19:58:30.886619Z","iopub.status.idle":"2024-06-08T19:58:42.861641Z","shell.execute_reply.started":"2024-06-08T19:58:30.886591Z","shell.execute_reply":"2024-06-08T19:58:42.860738Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1-649JNvw15TYDciHpMlJKXQ08_2lKJF4\nTo: /kaggle/working/rev_trainset_cmb.txt\n100%|██████████████████████████████████████| 9.98M/9.98M [00:00<00:00, 91.3MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# https://drive.google.com/file/d/1-8-Pv2lowjIAalgaY4gUMdYhVadPp0Gn/view?usp=sharing\n!gdown --id \"1-8-Pv2lowjIAalgaY4gUMdYhVadPp0Gn\"","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:58:42.863069Z","iopub.execute_input":"2024-06-08T19:58:42.863381Z","iopub.status.idle":"2024-06-08T19:58:44.906032Z","shell.execute_reply.started":"2024-06-08T19:58:42.863353Z","shell.execute_reply":"2024-06-08T19:58:44.905114Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1-8-Pv2lowjIAalgaY4gUMdYhVadPp0Gn\nTo: /kaggle/working/rev_valset_cmb.txt\n100%|███████████████████████████████████████| 2.62M/2.62M [00:00<00:00, 137MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# https://drive.google.com/file/d/1m11t37h2bLU2wmd41aTEQREGWsFJGyfj/view?usp=sharing\n!gdown --id \"1m11t37h2bLU2wmd41aTEQREGWsFJGyfj\"","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:58:44.908849Z","iopub.execute_input":"2024-06-08T19:58:44.909161Z","iopub.status.idle":"2024-06-08T19:58:47.240012Z","shell.execute_reply.started":"2024-06-08T19:58:44.909135Z","shell.execute_reply":"2024-06-08T19:58:47.239112Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1m11t37h2bLU2wmd41aTEQREGWsFJGyfj\nTo: /kaggle/working/spoiler_y.txt\n100%|████████████████████████████████████████| 277k/277k [00:00<00:00, 94.0MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# https://drive.google.com/file/d/1--PbeWSlq26rId939CNjGBWQV8Dcg6p5/view?usp=sharing\n!gdown --id \"1--PbeWSlq26rId939CNjGBWQV8Dcg6p5\"","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:58:47.241401Z","iopub.execute_input":"2024-06-08T19:58:47.241730Z","iopub.status.idle":"2024-06-08T19:58:48.964558Z","shell.execute_reply.started":"2024-06-08T19:58:47.241700Z","shell.execute_reply":"2024-06-08T19:58:48.963473Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1--PbeWSlq26rId939CNjGBWQV8Dcg6p5\nTo: /kaggle/working/spoiler_y_val.txt\n100%|██████████████████████████████████████| 71.7k/71.7k [00:00<00:00, 92.2MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BartTokenizer, BartForConditionalGeneration;\nfrom transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer;","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:58:48.965997Z","iopub.execute_input":"2024-06-08T19:58:48.966310Z","iopub.status.idle":"2024-06-08T19:58:56.032065Z","shell.execute_reply.started":"2024-06-08T19:58:48.966281Z","shell.execute_reply":"2024-06-08T19:58:56.031291Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2024-06-08 19:58:52.822067: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-08 19:58:52.822120: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-08 19:58:52.823521: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch;\nimport torch.nn as nn;\nimport torch.optim as optim;\nimport torch.nn.functional as F;\nfrom torch.utils.data import Dataset, DataLoader;","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:58:56.033184Z","iopub.execute_input":"2024-06-08T19:58:56.033731Z","iopub.status.idle":"2024-06-08T19:58:56.038614Z","shell.execute_reply.started":"2024-06-08T19:58:56.033704Z","shell.execute_reply":"2024-06-08T19:58:56.037764Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\");\nprint(device);","metadata":{"execution":{"iopub.status.busy":"2024-06-08T20:32:52.496534Z","iopub.execute_input":"2024-06-08T20:32:52.497312Z","iopub.status.idle":"2024-06-08T20:32:52.503670Z","shell.execute_reply.started":"2024-06-08T20:32:52.497280Z","shell.execute_reply":"2024-06-08T20:32:52.502600Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"model = BartForConditionalGeneration.from_pretrained('facebook/bart-base');\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-base');","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:58:56.039770Z","iopub.execute_input":"2024-06-08T19:58:56.040121Z","iopub.status.idle":"2024-06-08T19:58:57.655502Z","shell.execute_reply.started":"2024-06-08T19:58:56.040089Z","shell.execute_reply":"2024-06-08T19:58:57.654472Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(nn.Module):\n    def __init__(self,path_x,path_y,tokenizer,max_seq_length,max_target_length):\n        super().__init__();\n\n        self.max_seq_length = max_seq_length;\n        self.max_target_length = max_target_length;\n\n        with open(path_x,'r') as f:\n            self.x = f.readlines();\n        with open(path_y,'r') as f:\n            self.y = f.readlines();\n\n    def __len__(self):\n        return len(self.x);\n\n    def __getitem__(self,idx):\n        x = tokenizer(self.x[idx],max_length=self.max_seq_length,truncation=True,padding='max_length',return_tensors='pt');\n        y = tokenizer(self.y[idx],max_length=self.max_target_length,truncation=True,padding='max_length',return_tensors='pt');\n        \n        return {\n            'input_ids':x['input_ids'].flatten(),\n            'attention_mask':x['attention_mask'].flatten(),\n            'labels':y['input_ids'].flatten(),\n            'decoder_attention_mask':y['attention_mask'].flatten()\n        };","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:58:57.656932Z","iopub.execute_input":"2024-06-08T19:58:57.657256Z","iopub.status.idle":"2024-06-08T19:58:57.667405Z","shell.execute_reply.started":"2024-06-08T19:58:57.657230Z","shell.execute_reply":"2024-06-08T19:58:57.666544Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"training_dataset = CustomDataset(\n    path_x='/kaggle/working/rev_trainset_cmb.txt',\n    path_y='/kaggle/working/spoiler_y.txt',\n    tokenizer=tokenizer,\n    max_seq_length=512,\n    max_target_length=512\n);\n\nvalidation_dataset = CustomDataset(\n    path_x='/kaggle/working/rev_valset_cmb.txt',\n    path_y='/kaggle/working/spoiler_y_val.txt',\n    tokenizer=tokenizer,\n    max_seq_length=512,\n    max_target_length=512\n);","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:58:57.668592Z","iopub.execute_input":"2024-06-08T19:58:57.668957Z","iopub.status.idle":"2024-06-08T19:58:57.724450Z","shell.execute_reply.started":"2024-06-08T19:58:57.668925Z","shell.execute_reply":"2024-06-08T19:58:57.723736Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"args = Seq2SeqTrainingArguments(\n    output_dir='/kaggle/working/',\n    eval_strategy='epoch',\n    save_strategy='epoch',\n    learning_rate=2e-5,\n    gradient_accumulation_steps=2,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=5,\n    predict_with_generate=True,\n    fp16=True,\n);","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:58:57.725448Z","iopub.execute_input":"2024-06-08T19:58:57.725691Z","iopub.status.idle":"2024-06-08T19:58:57.830484Z","shell.execute_reply.started":"2024-06-08T19:58:57.725670Z","shell.execute_reply":"2024-06-08T19:58:57.829717Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=args,\n    train_dataset=training_dataset,\n    eval_dataset=validation_dataset,\n    tokenizer=tokenizer\n);","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:58:57.831574Z","iopub.execute_input":"2024-06-08T19:58:57.831877Z","iopub.status.idle":"2024-06-08T19:58:58.417676Z","shell.execute_reply.started":"2024-06-08T19:58:57.831852Z","shell.execute_reply":"2024-06-08T19:58:58.416695Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"trainer.train();","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:58:58.420694Z","iopub.execute_input":"2024-06-08T19:58:58.421020Z","iopub.status.idle":"2024-06-08T20:29:13.176481Z","shell.execute_reply.started":"2024-06-08T19:58:58.420994Z","shell.execute_reply":"2024-06-08T20:29:13.175293Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdippatel3102001\u001b[0m (\u001b[33mdip003\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240608_195900-omgr5xq5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dip003/huggingface/runs/omgr5xq5' target=\"_blank\">/kaggle/working/</a></strong> to <a href='https://wandb.ai/dip003/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dip003/huggingface' target=\"_blank\">https://wandb.ai/dip003/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dip003/huggingface/runs/omgr5xq5' target=\"_blank\">https://wandb.ai/dip003/huggingface/runs/omgr5xq5</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 29:50, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.689155</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.192398</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.085218</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.074331</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.367200</td>\n      <td>0.072432</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"}]},{"cell_type":"code","source":"val_dataloader = DataLoader(validation_dataset,batch_size=4,shuffle=True);","metadata":{"execution":{"iopub.status.busy":"2024-06-08T20:33:53.700015Z","iopub.execute_input":"2024-06-08T20:33:53.700462Z","iopub.status.idle":"2024-06-08T20:33:53.707741Z","shell.execute_reply.started":"2024-06-08T20:33:53.700427Z","shell.execute_reply":"2024-06-08T20:33:53.706644Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(val_dataloader));","metadata":{"execution":{"iopub.status.busy":"2024-06-08T20:37:48.260390Z","iopub.execute_input":"2024-06-08T20:37:48.261543Z","iopub.status.idle":"2024-06-08T20:37:48.313260Z","shell.execute_reply.started":"2024-06-08T20:37:48.261497Z","shell.execute_reply":"2024-06-08T20:37:48.311992Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"output_text = model.generate(batch['input_ids'].to(device),max_length=300,num_beams=5,early_stopping=True);","metadata":{"execution":{"iopub.status.busy":"2024-06-08T20:37:50.297665Z","iopub.execute_input":"2024-06-08T20:37:50.298379Z","iopub.status.idle":"2024-06-08T20:37:50.756203Z","shell.execute_reply.started":"2024-06-08T20:37:50.298344Z","shell.execute_reply":"2024-06-08T20:37:50.755103Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"ids = 0;\ntxt = tokenizer.decode(output_text[ids],skip_special_tokens=True);\nprint(\"generated :-\",txt);\nprint(\"original :- \",tokenizer.decode(batch['labels'][ids],skip_special_tokens=True));","metadata":{"execution":{"iopub.status.busy":"2024-06-08T20:37:54.799576Z","iopub.execute_input":"2024-06-08T20:37:54.800067Z","iopub.status.idle":"2024-06-08T20:37:54.826041Z","shell.execute_reply.started":"2024-06-08T20:37:54.800026Z","shell.execute_reply":"2024-06-08T20:37:54.824935Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"generated :- the future of fast food has arrived\n\noriginal :-  robots\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}